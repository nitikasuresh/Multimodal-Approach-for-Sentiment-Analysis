{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfbacc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#!pip install nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "358b1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598ef3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input - Utterance or Column '1'\n",
    "# Emotion(7) - Output 1 and Column '3'\n",
    "# Sentiment(3) - Output 2 and Column '4'\n",
    "df1 = pd.read_csv('data1.csv')\n",
    "df2 = pd.read_csv('data2.csv')\n",
    "df3 = pd.read_csv('data3.csv')\n",
    "df4 = pd.read_csv('data4.csv')\n",
    "\n",
    "frames = [df1,df2,df3,df4]\n",
    "data = pd.concat(frames) #complete dataset\n",
    "\n",
    "mat =np.asarray([]) #emo\n",
    "mat1 =np.asarray([]) #senti\n",
    "data = np.asarray(data[['1','3','4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf3a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca030ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[:,0], data[:,1:3], test_size=0.2, shuffle = True)\n",
    "\n",
    "X_train_copy1 = X_train.copy()\n",
    "X_test_copy1 = X_test.copy()\n",
    "\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "# emotion (7)\n",
    "y_train_emo = y_train[:,0] *1.0\n",
    "y_train_emo = y_train_emo.astype('int')\n",
    "y_test_emo = y_test[:,0] *1.0\n",
    "y_test_emo = y_test_emo.astype('int')\n",
    "\n",
    "# sentiment(3)\n",
    "y_train_senti = y_train[:,1] *1.0\n",
    "y_train_senti = y_train_senti.astype('int')\n",
    "y_test_senti = y_test[:,1] *1.0\n",
    "y_test_senti = y_test_senti.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aded096",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6a0cb",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ec2af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5163227572939671\n",
      "Testing Accuracy :  0.4759330168986745\n",
      "[[1089   35    3   20   77    5   57]\n",
      " [ 183  104    2    6   22    2   11]\n",
      " [  43    6    4    7    4    0    6]\n",
      " [ 124   10    4   20   21    3   19]\n",
      " [ 282   26    2    9  116    1   22]\n",
      " [  47    6    0    4    6    4   14]\n",
      " [ 207   25    2    8   23    2   49]]\n",
      "F1-Score :  0.5054704595185996\n",
      "Time Taken : 11.005656719207764\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5534380337537061\n",
      "Testing Accuracy :  0.5069356361267334\n",
      "[[959 116 211]\n",
      " [299 193 115]\n",
      " [427  72 350]]\n",
      "F1-Score :  0.5477753464624362\n",
      "Time Taken : 5.83949875831604\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    print(\"Multinomial Logistic Regression\")\n",
    "    start = time.time()\n",
    "    logreg = LogisticRegression(multi_class='multinomial', max_iter = 1e4)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(logreg, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    accuracy_test_data = cross_val_score(logreg, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = logistic_regression(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = logistic_regression(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa93a5",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db22aeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.5008210844067121\n",
      "Testing Accuracy :  0.482132743009852\n",
      "[[1195   10    1    1   48    0   31]\n",
      " [ 226   77    0    0   21    0    6]\n",
      " [  59    3    0    2    2    0    4]\n",
      " [ 165    7    0    6   16    0    7]\n",
      " [ 346   17    0    2   83    0   10]\n",
      " [  65    1    0    2    3    1    9]\n",
      " [ 255   15    0    2   14    0   30]]\n",
      "F1-Score :  0.5076586433260394\n",
      "Time Taken : 0.04716897010803223\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.5538030802408093\n",
      "Testing Accuracy :  0.5109482403307939\n",
      "[[1015   72  199]\n",
      " [ 319  162  126]\n",
      " [ 438   54  357]]\n",
      "F1-Score :  0.5594456601021153\n",
      "Time Taken : 0.024672269821166992\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Multinomial Naive Bayes\")\n",
    "    classifier = MultinomialNB();\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(classifier, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    \n",
    "    # predicting test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(classifier, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    \n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = naive_bayes(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = naive_bayes(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6c3d66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.16322757e-01, 1.69595982e-02, 4.75933017e-01, 1.33925514e-02,\n",
       "        5.05470460e-01, 1.10056567e+01],\n",
       "       [5.00821084e-01, 5.06851321e-03, 4.82132743e-01, 6.26946602e-03,\n",
       "        5.07658643e-01, 4.71689701e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.reshape(2,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a250832",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b950977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5095752998789136\n",
      "Testing Accuracy :  0.48541010197705187\n",
      "[[1166   45    2    6   40    0   27]\n",
      " [ 174  124    4    2   14    2   10]\n",
      " [  57    2    4    3    2    0    2]\n",
      " [ 155   17    2   13    7    0    7]\n",
      " [ 326   28    3    1   84    0   16]\n",
      " [  65    5    0    1    4    1    5]\n",
      " [ 243   28    0    2   11    0   32]]\n",
      "F1-Score :  0.5193289569657185\n",
      "Time Taken : 89.89220762252808\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5475104552855463\n",
      "Testing Accuracy :  0.5124021113371359\n",
      "[[1025   92  169]\n",
      " [ 322  179  106]\n",
      " [ 471   52  326]]\n",
      "F1-Score :  0.5579868708971554\n",
      "Time Taken : 84.55184435844421\n"
     ]
    }
   ],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Random Forest Classifier\")\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(rf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "\n",
    "    # predicting test set results\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(rf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = random_forest(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup= random_forest(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c212e10",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e39625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.4906988383108432\n",
      "Testing Accuracy :  0.4690000398867217\n",
      "[[1269    2    0    1    8    0    6]\n",
      " [ 294   30    0    0    5    0    1]\n",
      " [  63    1    0    2    2    0    2]\n",
      " [ 191    7    0    1    2    0    0]\n",
      " [ 406    6    0    0   39    1    6]\n",
      " [  78    1    0    0    1    0    1]\n",
      " [ 297   10    0    1    3    0    5]]\n",
      "F1-Score :  0.49015317286652077\n",
      "Time Taken : 71.88595509529114\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.5205189213545545\n",
      "Testing Accuracy :  0.4726476805871325\n",
      "[[1200   18   68]\n",
      " [ 480   69   58]\n",
      " [ 664   20  165]]\n",
      "F1-Score :  0.5229759299781181\n",
      "Time Taken : 49.92970061302185\n"
     ]
    }
   ],
   "source": [
    "def sv_classifier(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Support Vector Classifier\")\n",
    "    clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(clf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    \n",
    "    # predicting test set results\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(clf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = sv_classifier(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = sv_classifier(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140bee0",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c700f2",
   "metadata": {},
   "source": [
    "# Feature Engineering - 1. Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c441026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_remover(x):\n",
    "    X_t1 = x\n",
    "    for i in range(len(x)):\n",
    "        X_t1[i] = [char for char in x[i] if char not in string.punctuation]\n",
    "        X_t1[i]=''.join(X_t1[i])\n",
    "    return X_t1\n",
    "\n",
    "#All useless punctuations are removed\n",
    "X_tr1 = punctuation_remover(X_train_copy1)\n",
    "X_te1 = punctuation_remover(X_test_copy1)\n",
    "\n",
    "# train1 and test1 - after punctuations removed \n",
    "X_train1 = vect.fit_transform(X_tr1) ##fit and transform at the same time\n",
    "X_test1 = vect.transform(X_te1) ##only transform the test set so that fitting can be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf589cdb",
   "metadata": {},
   "source": [
    "# After 1st Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa66e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa49240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5161398183746162\n",
      "Testing Accuracy :  0.4741141823886828\n",
      "[[1078   39    5   25   83    4   52]\n",
      " [ 167  124    1    5   19    2   12]\n",
      " [  44    7    3    7    3    0    6]\n",
      " [ 127   10    4   18   21    3   18]\n",
      " [ 280   25    2    9  120    1   21]\n",
      " [  45    7    0    6    6    3   14]\n",
      " [ 210   21    3   10   24    2   46]]\n",
      "F1-Score :  0.5076586433260394\n",
      "Time Taken : 14.585546493530273\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5506103991277458\n",
      "Testing Accuracy :  0.5018294709691145\n",
      "[[966 120 200]\n",
      " [309 186 112]\n",
      " [423  83 343]]\n",
      "F1-Score :  0.5452224653537564\n",
      "Time Taken : 5.946001052856445\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = logistic_regression(X_train1, y_train_emo, X_test1, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = logistic_regression(X_train1, y_train_senti, X_test1, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8643b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06362282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.49571413310188495\n",
      "Testing Accuracy :  0.4795793280416949\n",
      "[[1193   10    1    3   48    0   31]\n",
      " [ 226   78    0    2   18    0    6]\n",
      " [  61    2    0    1    2    0    4]\n",
      " [ 169    5    0    7   14    0    6]\n",
      " [ 355   13    0    3   78    0    9]\n",
      " [  70    1    0    2    1    0    7]\n",
      " [ 254   13    0    3   15    0   31]]\n",
      "F1-Score :  0.5058351568198395\n",
      "Time Taken : 0.06742572784423828\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.5496082463427804\n",
      "Testing Accuracy :  0.5054811003416961\n",
      "[[1025   70  191]\n",
      " [ 330  150  127]\n",
      " [ 446   45  358]]\n",
      "F1-Score :  0.5590809628008753\n",
      "Time Taken : 0.04668092727661133\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = naive_bayes(X_train1, y_train_emo, X_test1, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = naive_bayes(X_train1, y_train_senti, X_test1, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d8afb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0fccd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5103952203933873\n",
      "Testing Accuracy :  0.476293991730153\n",
      "[[1147   49    1   13   43    0   33]\n",
      " [ 181  118    3    3   13    2   10]\n",
      " [  55    4    3    3    3    0    2]\n",
      " [ 160   16    0   12    7    1    5]\n",
      " [ 337   28    2    0   78    0   13]\n",
      " [  68    4    0    1    3    1    4]\n",
      " [ 245   27    0    1    9    0   34]]\n",
      "F1-Score :  0.5080233406272794\n",
      "Time Taken : 95.37261414527893\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5421297814667619\n",
      "Testing Accuracy :  0.506564024836132\n",
      "[[1031   84  171]\n",
      " [ 330  176  101]\n",
      " [ 481   48  320]]\n",
      "F1-Score :  0.5568927789934355\n",
      "Time Taken : 86.31191730499268\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = random_forest(X_train1, y_train_emo, X_test1, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = random_forest(X_train1, y_train_senti, X_test1, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d92edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6adb7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.4886924959294947\n",
      "Testing Accuracy :  0.4690000398867217\n",
      "[[1268    1    0    1   11    0    5]\n",
      " [ 292   34    0    0    3    0    1]\n",
      " [  63    1    0    2    2    0    2]\n",
      " [ 191    6    0    1    3    0    0]\n",
      " [ 411    6    0    0   34    1    6]\n",
      " [  75    1    0    0    1    2    2]\n",
      " [ 301    6    0    1    2    1    5]]\n",
      "F1-Score :  0.49015317286652077\n",
      "Time Taken : 64.53780722618103\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.5171448393225981\n",
      "Testing Accuracy :  0.47155544919096437\n",
      "[[1199   18   69]\n",
      " [ 475   65   67]\n",
      " [ 670   22  157]]\n",
      "F1-Score :  0.5182348650619986\n",
      "Time Taken : 45.721609354019165\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = sv_classifier(X_train1, y_train_emo, X_test1, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = sv_classifier(X_train1, y_train_senti, X_test1, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2b6ae",
   "metadata": {},
   "source": [
    "# Feature Engineering - 2. Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4ed6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords = set(stopwords.words('english'))\n",
    "#print(StopWords)\n",
    "\n",
    "#train2 and test2 after stopwords removed \n",
    "def stopwords_remover(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = [word for word in x[i].split() if word.lower() not in StopWords]\n",
    "        \n",
    "    a = \"\"\n",
    "    for i in range(len(x)):\n",
    "        for word in x[i]:\n",
    "            #print(word)\n",
    "            a = a +word +\" \"\n",
    "        x[i]=a\n",
    "        a=\"\"\n",
    "    return x\n",
    "\n",
    "X_tr2 = stopwords_remover(X_tr1.copy())\n",
    "X_te2 = stopwords_remover(X_te1.copy())\n",
    "\n",
    "#print (X_tr2)\n",
    "X_train2 = vect.fit_transform(X_tr2.copy()) ##fit and transform at the same time\n",
    "X_test2 = vect.transform(X_te2.copy()) ##only transform the test set so that fitting can be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaade17",
   "metadata": {},
   "source": [
    "# After 2nd Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31ff6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e237c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5069303131992446\n",
      "Testing Accuracy :  0.4744778163349421\n",
      "[[1099   31    3   19   77    3   54]\n",
      " [ 203   82    1    6   21    1   16]\n",
      " [  47    5    2    7    5    0    4]\n",
      " [ 124   11    7   19   18    3   19]\n",
      " [ 294   28    0    9  109    0   18]\n",
      " [  48    7    0    4   11    2    9]\n",
      " [ 214   19    1   11   22    0   49]]\n",
      "F1-Score :  0.49671772428884026\n",
      "Time Taken : 9.778442621231079\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5448653439031375\n",
      "Testing Accuracy :  0.49271269594352046\n",
      "[[979 104 203]\n",
      " [327 174 106]\n",
      " [448  85 316]]\n",
      "F1-Score :  0.5357403355215171\n",
      "Time Taken : 4.8530964851379395\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = logistic_regression(X_train2, y_train_emo, X_test2, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = logistic_regression(X_train2, y_train_senti, X_test2, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ccc5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "872fb2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.4910635522573067\n",
      "Testing Accuracy :  0.4828553574515044\n",
      "[[1187   10    0    3   53    0   33]\n",
      " [ 243   56    1    1   20    0    9]\n",
      " [  58    4    0    2    4    0    2]\n",
      " [ 165   11    0    6   13    0    6]\n",
      " [ 352   12    0    3   81    0   10]\n",
      " [  62    2    0    3    5    1    8]\n",
      " [ 249   15    0    3   20    0   29]]\n",
      "F1-Score :  0.4959883296863603\n",
      "Time Taken : 0.048004865646362305\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.5353822409165485\n",
      "Testing Accuracy :  0.5025560740829378\n",
      "[[1017   82  187]\n",
      " [ 344  152  111]\n",
      " [ 458   67  324]]\n",
      "F1-Score :  0.5444930707512764\n",
      "Time Taken : 0.03200340270996094\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = naive_bayes(X_train2, y_train_emo, X_test2, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = naive_bayes(X_train2, y_train_senti, X_test2, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3760e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ee2439d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.4720973462841285\n",
      "Testing Accuracy :  0.4445760706260885\n",
      "[[1014   76    4   34   89    4   65]\n",
      " [ 180   91    2    5   26    3   23]\n",
      " [  39    9    3    6    8    1    4]\n",
      " [ 117   24    0   24   20    2   14]\n",
      " [ 294   29    2   10   99    0   24]\n",
      " [  53    5    0    6    6    3    8]\n",
      " [ 182   35    2    8   34    1   54]]\n",
      "F1-Score :  0.4697301239970824\n",
      "Time Taken : 104.84589457511902\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5183305129730339\n",
      "Testing Accuracy :  0.48397019132330843\n",
      "[[947 148 191]\n",
      " [298 199 110]\n",
      " [447 103 299]]\n",
      "F1-Score :  0.5269876002917578\n",
      "Time Taken : 97.47548651695251\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = random_forest(X_train2, y_train_emo, X_test2, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = random_forest(X_train2, y_train_senti, X_test2, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a0c4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0f0d1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.4870510753325094\n",
      "Testing Accuracy :  0.46936500339037135\n",
      "[[1265    1    0    1   13    0    6]\n",
      " [ 295   30    0    0    4    0    1]\n",
      " [  63    1    0    2    2    0    2]\n",
      " [ 190    6    0    1    3    0    1]\n",
      " [ 416    4    0    0   31    1    6]\n",
      " [  75    1    0    0    2    1    2]\n",
      " [ 300    7    0    1    3    1    4]]\n",
      "F1-Score :  0.48577680525164113\n",
      "Time Taken : 44.66665840148926\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.5142265458047712\n",
      "Testing Accuracy :  0.4697293021153259\n",
      "[[1206   19   61]\n",
      " [ 487   60   60]\n",
      " [ 678   20  151]]\n",
      "F1-Score :  0.5167760758570387\n",
      "Time Taken : 31.804723978042603\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = sv_classifier(X_train2, y_train_emo, X_test2, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = sv_classifier(X_train2, y_train_senti, X_test2, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "322cf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_emo = np.reshape(mat,(12,6))\n",
    "mat_senti = np.reshape(mat1,(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2a76c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after lemma - we become 16 by 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5d794",
   "metadata": {},
   "source": [
    "# Feature Engineering - 3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e58f0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stem_sentences(x):\n",
    "    sen_list = []\n",
    "    for sentence in x:\n",
    "        tokens = sentence.split()\n",
    "        stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "        stemmed_string =  ' '.join(stemmed_tokens)\n",
    "        sen_list.append(stemmed_string)\n",
    "    sen_list_arr = np.asarray(sen_list)\n",
    "    return sen_list_arr\n",
    "        \n",
    "\n",
    "#Stemming the sentences\n",
    "X_tr3 = stem_sentences(X_tr2.copy())\n",
    "X_te3 = stem_sentences(X_te2.copy())\n",
    "\n",
    "#Train3 and test3 after stemming is done\n",
    "X_train3 = vect.fit_transform(X_tr3.copy()) ##fit and transform at the same time\n",
    "X_test3 = vect.transform(X_te3.copy()) ##only transform the test set so that fitting can be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38f586",
   "metadata": {},
   "source": [
    "# After 3rd Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb5bda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb47edc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5043770246009409\n",
      "Testing Accuracy :  0.4708261869623603\n",
      "[[1099   28    4   28   77    1   49]\n",
      " [ 203   84    1    6   22    0   14]\n",
      " [  49    4    1    9    3    0    4]\n",
      " [ 124   13    6   14   18    4   22]\n",
      " [ 296   21    1    9  112    0   19]\n",
      " [  48    7    0    6   10    3    7]\n",
      " [ 213   18    2    9   25    0   49]]\n",
      "F1-Score :  0.49671772428884026\n",
      "Time Taken : 10.94667911529541\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5434073194688827\n",
      "Testing Accuracy :  0.49489582917846653\n",
      "[[988 107 191]\n",
      " [326 176 105]\n",
      " [445  85 319]]\n",
      "F1-Score :  0.5408460977388767\n",
      "Time Taken : 4.382315158843994\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = logistic_regression(X_train3, y_train_emo, X_test3, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = logistic_regression(X_train3, y_train_senti, X_test3, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c1396f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a29bdc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.4930701856117148\n",
      "Testing Accuracy :  0.47957733370560945\n",
      "[[1180   14    0    8   54    0   30]\n",
      " [ 237   59    0    1   19    0   14]\n",
      " [  57    4    1    2    4    0    2]\n",
      " [ 167    9    0    4   14    0    7]\n",
      " [ 350   13    0    1   84    0   10]\n",
      " [  57    4    0    4    8    1    7]\n",
      " [ 239   16    0    5   22    0   34]]\n",
      "F1-Score :  0.49708242159008026\n",
      "Time Taken : 0.04028892517089844\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.5420396213858548\n",
      "Testing Accuracy :  0.5007206201055668\n",
      "[[1016   86  184]\n",
      " [ 346  148  113]\n",
      " [ 438   68  343]]\n",
      "F1-Score :  0.549598832968636\n",
      "Time Taken : 0.024397611618041992\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = naive_bayes(X_train3, y_train_emo, X_test3, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = naive_bayes(X_train3, y_train_senti, X_test3, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30ab83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ff28cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.47227883033818135\n",
      "Testing Accuracy :  0.44530865674816855\n",
      "[[1018   79    2   29   90    4   64]\n",
      " [ 183   86    2    4   26    4   25]\n",
      " [  42   10    3    5    6    1    3]\n",
      " [ 118   28    0   22   19    1   13]\n",
      " [ 283   35    2    9  101    1   27]\n",
      " [  48    6    0    7   10    4    6]\n",
      " [ 174   41    1    9   33    2   56]]\n",
      "F1-Score :  0.47045951859956237\n",
      "Time Taken : 90.59397435188293\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5212480582744217\n",
      "Testing Accuracy :  0.47959395317298875\n",
      "[[923 166 197]\n",
      " [298 203 106]\n",
      " [427 116 306]]\n",
      "F1-Score :  0.5222465353756383\n",
      "Time Taken : 84.82450985908508\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = random_forest(X_train3, y_train_emo, X_test3, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = random_forest(X_train3, y_train_senti, X_test3, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a171c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46320691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.48686888462959754\n",
      "Testing Accuracy :  0.4682707776581176\n",
      "[[1262    1    0    3   17    0    3]\n",
      " [ 285   35    0    0    8    0    2]\n",
      " [  66    1    0    2    1    0    0]\n",
      " [ 188    6    0    2    4    0    1]\n",
      " [ 410    7    0    0   35    1    5]\n",
      " [  74    1    0    0    2    1    3]\n",
      " [ 288    9    0    3    7    1    8]]\n",
      "F1-Score :  0.4897884755652808\n",
      "Time Taken : 43.8143093585968\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.5159593319424821\n",
      "Testing Accuracy :  0.471916424022443\n",
      "[[1181   24   81]\n",
      " [ 485   63   59]\n",
      " [ 651   21  177]]\n",
      "F1-Score :  0.5182348650619986\n",
      "Time Taken : 31.48685574531555\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = sv_classifier(X_train3, y_train_emo, X_test3, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = sv_classifier(X_train3, y_train_senti, X_test3, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5433a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_emo = np.reshape(mat,(16,6))\n",
    "mat_senti = np.reshape(mat1,(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c479dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.16322757e-01, 1.69595982e-02, 4.75933017e-01, 1.33925514e-02,\n",
       "        5.05470460e-01, 1.10056567e+01],\n",
       "       [5.00821084e-01, 5.06851321e-03, 4.82132743e-01, 6.26946602e-03,\n",
       "        5.07658643e-01, 4.71689701e-02],\n",
       "       [5.09575300e-01, 3.52672472e-03, 4.85410102e-01, 1.21348397e-02,\n",
       "        5.19328957e-01, 8.98922076e+01],\n",
       "       [4.90698838e-01, 3.96484120e-03, 4.69000040e-01, 1.01967734e-03,\n",
       "        4.90153173e-01, 7.18859551e+01],\n",
       "       [5.16139818e-01, 1.46074519e-02, 4.74114182e-01, 1.42242029e-02,\n",
       "        5.07658643e-01, 1.45855465e+01],\n",
       "       [4.95714133e-01, 3.01903737e-03, 4.79579328e-01, 5.71497242e-03,\n",
       "        5.05835157e-01, 8.37564468e-02],\n",
       "       [5.10395220e-01, 4.49274225e-03, 4.76293992e-01, 1.52347223e-02,\n",
       "        5.08023341e-01, 9.53726141e+01],\n",
       "       [4.88692496e-01, 3.80798788e-03, 4.69000040e-01, 1.01967734e-03,\n",
       "        4.90153173e-01, 6.45378072e+01],\n",
       "       [5.06930313e-01, 1.09699352e-02, 4.74477816e-01, 1.94884836e-02,\n",
       "        4.96717724e-01, 9.77844262e+00],\n",
       "       [4.91063552e-01, 3.15955411e-03, 4.82855357e-01, 7.77018893e-03,\n",
       "        4.95988330e-01, 4.80048656e-02],\n",
       "       [4.72097346e-01, 1.37280565e-02, 4.44576071e-01, 1.29390078e-02,\n",
       "        4.69730124e-01, 1.04845895e+02],\n",
       "       [4.87051075e-01, 3.40664253e-03, 4.69365003e-01, 4.73855261e-04,\n",
       "        4.85776805e-01, 4.46666584e+01],\n",
       "       [5.04377025e-01, 9.82491678e-03, 4.70826187e-01, 1.82825081e-02,\n",
       "        4.96717724e-01, 1.09466791e+01],\n",
       "       [4.93070186e-01, 4.52935512e-03, 4.79577334e-01, 7.11881903e-03,\n",
       "        4.97082422e-01, 4.02889252e-02],\n",
       "       [4.72278830e-01, 7.34767464e-03, 4.45308657e-01, 1.74111407e-02,\n",
       "        4.70459519e-01, 9.05939744e+01],\n",
       "       [4.86868885e-01, 2.70141993e-03, 4.68270778e-01, 1.07922967e-03,\n",
       "        4.89788476e-01, 4.38143094e+01]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b528655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55343803, 0.01058488, 0.50693564],\n",
       "       [0.55380308, 0.0039437 , 0.51094824],\n",
       "       [0.54751046, 0.0046041 , 0.51240211],\n",
       "       [0.52051892, 0.00614652, 0.47264768],\n",
       "       [0.5506104 , 0.01333102, 0.50182947],\n",
       "       [0.54960825, 0.00476774, 0.5054811 ],\n",
       "       [0.54212978, 0.01137655, 0.50656402],\n",
       "       [0.51714484, 0.00619722, 0.47155545],\n",
       "       [0.54486534, 0.00745299, 0.4927127 ],\n",
       "       [0.53538224, 0.00415154, 0.50255607],\n",
       "       [0.51833051, 0.00839856, 0.48397019],\n",
       "       [0.51422655, 0.00594202, 0.4697293 ],\n",
       "       [0.54340732, 0.00767265, 0.49489583],\n",
       "       [0.54203962, 0.00399517, 0.50072062],\n",
       "       [0.52124806, 0.00516952, 0.47959395],\n",
       "       [0.51595933, 0.0058084 , 0.47191642]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_senti[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ada4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "savetxt('mat_senti.csv', mat_senti, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8eb9bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "savetxt('mat_emo.csv', mat_emo, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14673f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
