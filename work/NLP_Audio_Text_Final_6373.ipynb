{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3a5cc5-39bc-4723-85fe-d29d9bd4a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c81a916-76ed-4a4e-a392-e9cf6e63ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat =np.asarray([]) #emo\n",
    "mat1 =np.asarray([]) #senti\n",
    "data = pd.read_csv('audio_6373_features.csv')\n",
    "data = np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17409d1c-3695-4ad2-80c7-cd716315f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data[:,4:6] #emotions #sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1f0075-74f4-4e82-8f51-bc8fb8f144a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = data[:,13:] #input-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0859a907-5fae-4947-a967-d6240e51c074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13837, 6373)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33c0b5f-9d32-47ec-aad1-7035d2ea6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inp, output, test_size=0.2, shuffle = True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_copy1 = X_train.copy()\n",
    "X_test_copy1 = X_test.copy()\n",
    "\n",
    "# emotion (7)\n",
    "y_train_emo = y_train[:,0] *1.0\n",
    "y_train_emo = y_train_emo.astype('float')\n",
    "y_test_emo = y_test[:,0] *1.0\n",
    "y_test_emo = y_test_emo.astype('float')\n",
    "\n",
    "# sentiment(3)\n",
    "y_train_senti = y_train[:,1] *1.0\n",
    "y_train_senti = y_train_senti.astype('float')\n",
    "y_test_senti = y_test[:,1] *1.0\n",
    "y_test_senti = y_test_senti.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1d7a9c1-eadd-48c0-a336-73f3745c598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.4742073507495129\n",
      "Testing Accuracy :  0.4877204091891292\n",
      "[[1031   91    0   15  140    0   60]\n",
      " [ 213   39    0    4   37    0   20]\n",
      " [  45    6    0    1    3    0    9]\n",
      " [ 142   22    0    7   17    0   10]\n",
      " [ 344   27    0    3   49    0   40]\n",
      " [  57    6    0    1    7    0    8]\n",
      " [ 193   30    0    4   35    0   52]]\n",
      "F1-Score :  0.42557803468208094\n",
      "Time Taken : 359.60492420196533\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5070915845474164\n",
      "Testing Accuracy :  0.507587102839125\n",
      "[[567  88 682]\n",
      " [213  62 341]\n",
      " [253  51 511]]\n",
      "F1-Score :  0.41184971098265893\n",
      "Time Taken : 298.87330412864685\n"
     ]
    }
   ],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Random Forest Classifier\")\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(rf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "\n",
    "    # predicting test set results\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(rf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = random_forest(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup= random_forest(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32beaf22-048e-45e8-8617-78a9fa762d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat =np.asarray([]) #emo\n",
    "mat1 =np.asarray([]) #senti\n",
    "data = pd.read_csv('audio_6373_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee5c8245-da43-40e6-809e-acacda476817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data1.csv')\n",
    "df2 = pd.read_csv('data2.csv')\n",
    "df3 = pd.read_csv('data3.csv')\n",
    "df4 = pd.read_csv('data4.csv')\n",
    "\n",
    "frames = [df1,df2,df3,df4]\n",
    "data_t = pd.concat(frames) #complete dataset\n",
    "\n",
    "mat =np.asarray([]) #emo\n",
    "mat1 =np.asarray([]) #senti\n",
    "data_text = np.asarray(data_t[['1','3','4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4e19ad-2979-4040-955e-058a3cd0f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"string\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af388ab-916d-48c4-a22a-15e551d786a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = data_t.rename(columns={\"11\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a0cec1a-7d18-4826-810c-118ca51ea1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeddata = data_t.merge(data, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e85eec6-fff7-4456-b953-d320002d33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeddata = np.array(mergeddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091abf06-1f5a-406f-8f7b-40046bfe6389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word vectors: 684830\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "total_vectors = len(nlp.vocab.vectors)\n",
    "print('Total word vectors:', total_vectors)\n",
    "doc_glove_vectors = np.array([nlp(str(doc)).vector for doc in mergeddata[:,2]])\n",
    "X_glove = np.zeros((doc_glove_vectors.shape[0], 300))\n",
    "for i in range(doc_glove_vectors.shape[0]):\n",
    "    if (doc_glove_vectors[i].shape[0] == 300):\n",
    "        X_glove[i,:] = doc_glove_vectors[i][:]\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e89425-d746-4fff-9e14-a3a39b8d70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f54de6ee-0898-4cf9-bc33-557adf7dc848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=300, svd_solver='full')\n",
    "X_pca = pca.fit_transform(mergeddata[:,-6373:].copy())\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb400ca-e104-4cc0-8823-2015004283e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_combined = np.concatenate((scaler.fit_transform(X_glove), scaler.fit_transform(X_pca)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbbee2f2-b4f9-43fc-882f-c8a244ca24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feat_combined, mergeddata[:,4:6], test_size=0.2, shuffle = True)\n",
    "# emotion (7)\n",
    "y_train_emo = y_train[:,0] *1.0\n",
    "y_train_emo = y_train_emo.astype('float')\n",
    "y_test_emo = y_test[:,0] *1.0\n",
    "y_test_emo = y_test_emo.astype('float')\n",
    "\n",
    "# sentiment(3)\n",
    "y_train_senti = y_train[:,1] *1.0\n",
    "y_train_senti = y_train_senti.astype('float')\n",
    "y_test_senti = y_test[:,1] *1.0\n",
    "y_test_senti = y_test_senti.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94d11a3f-49db-4efa-aa20-6cf495418846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5638271999529756\n",
      "Testing Accuracy :  0.548413314967261\n",
      "[[1257   16    0    0   26    0    5]\n",
      " [ 154   95    0    0   41    0   20]\n",
      " [  56    3    3    0    8    0    2]\n",
      " [ 177    5    0    6    9    0    7]\n",
      " [ 253    9    1    0  175    0   16]\n",
      " [  63    5    0    0    6    1    5]\n",
      " [ 223   19    0    1   55    0   46]]\n",
      "F1-Score :  0.571893063583815\n",
      "Time Taken : 93.20202088356018\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.6171286040319359\n",
      "Testing Accuracy :  0.6072907214341206\n",
      "[[1193   39   72]\n",
      " [ 249  213  150]\n",
      " [ 460   62  330]]\n",
      "F1-Score :  0.6271676300578035\n",
      "Time Taken : 79.05316805839539\n"
     ]
    }
   ],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Random Forest Classifier\")\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(rf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "\n",
    "    # predicting test set results\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(rf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = random_forest(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup= random_forest(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12d47948-b4ed-4b55-8d61-d2f9bf7665e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.5904780856815949\n",
      "Testing Accuracy :  0.5567172168872119\n",
      "F1-Score :  0.5863439306358381\n",
      "[[1199   16    0    1   36    0   21]\n",
      " [ 120  130    0    0   39    0   24]\n",
      " [  54    5    1    0    5    0   14]\n",
      " [ 176   10    0   10   10    0   15]\n",
      " [ 239   22    0    0  199    0   37]\n",
      " [  46    7    0    0    3    1    8]\n",
      " [ 157   28    0    2   50    0   83]]\n",
      "Time Taken : 231.63975143432617\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.6527238037857107\n",
      "Testing Accuracy :  0.6062116058780136\n",
      "F1-Score :  0.6488439306358381\n",
      "[[1133   35  105]\n",
      " [ 238  259  146]\n",
      " [ 375   73  404]]\n",
      "Time Taken : 193.7278118133545\n"
     ]
    }
   ],
   "source": [
    "def sv_classifier(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Support Vector Classifier\")\n",
    "    clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(clf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    \n",
    "    # predicting test set results\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(clf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(cm)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = sv_classifier(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = sv_classifier(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8f7ea-20fc-4a33-967a-b17ff4adc95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
