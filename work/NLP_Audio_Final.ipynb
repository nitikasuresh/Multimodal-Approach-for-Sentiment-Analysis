{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83818940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a222d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat =np.asarray([]) #emo\n",
    "mat1 =np.asarray([]) #senti\n",
    "data = pd.read_csv('audio_features.csv')\n",
    "data = np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d67cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data[:,4:6] #emotions #sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a38638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = data[:,13:] #input-features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2985e25",
   "metadata": {},
   "source": [
    "# Train_Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e2805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inp, output, test_size=0.2, shuffle = True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_copy1 = X_train.copy()\n",
    "X_test_copy1 = X_test.copy()\n",
    "\n",
    "# emotion (7)\n",
    "y_train_emo = y_train[:,0] *1.0\n",
    "y_train_emo = y_train_emo.astype('float')\n",
    "y_test_emo = y_test[:,0] *1.0\n",
    "y_test_emo = y_test_emo.astype('float')\n",
    "\n",
    "# sentiment(3)\n",
    "y_train_senti = y_train[:,1] *1.0\n",
    "y_train_senti = y_train_senti.astype('float')\n",
    "y_test_senti = y_test[:,1] *1.0\n",
    "y_test_senti = y_test_senti.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09d30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c4b9069",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87679a8c",
   "metadata": {},
   "source": [
    "#1. Lot of Feature Engineering is required.\n",
    "\n",
    "#2. If the independent features are correlated with each other it may affect the performance of the classifier.\n",
    "\n",
    "#3. It is quite sensitive to noise and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67066a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.4264081329464223\n",
      "Testing Accuracy :  0.383663728344834\n",
      "[[926  44  11  47 128  11 131]\n",
      " [136  53   4  10  47   2  68]\n",
      " [ 50   3   1   1   7   0  17]\n",
      " [102   9   4  20  27   2  28]\n",
      " [238  21   6  17  90   5  80]\n",
      " [ 31   7   0   4  14   4  22]\n",
      " [124  12   6  10  51   3 108]]\n",
      "F1-Score :  0.43836615609044494\n",
      "Time Taken : 283.76397490501404\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.49516544104657195\n",
      "Testing Accuracy :  0.43799675587996756\n",
      "[[883 140 275]\n",
      " [283 151 167]\n",
      " [332 133 378]]\n",
      "F1-Score :  0.5149525893508388\n",
      "Time Taken : 132.4779531955719\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    print(\"Multinomial Logistic Regression\")\n",
    "    start = time.time()\n",
    "    logreg = LogisticRegression(penalty='l2',multi_class='multinomial', max_iter = 1e4, solver = 'lbfgs')\n",
    "    #penalty to handle size better\n",
    "    \n",
    "    #https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451\n",
    "    \n",
    "    logreg.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(logreg, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    accuracy_test_data = cross_val_score(logreg, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = logistic_regression(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = logistic_regression(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd96496d",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53d63e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.31889587362790617\n",
      "Testing Accuracy :  0.32969167564117907\n",
      "[[541 256   0 321  19   8 153]\n",
      " [102 102   0  50  15   3  48]\n",
      " [ 35  13   0  13   2   1  15]\n",
      " [ 64  16   0  70   4   1  37]\n",
      " [157 104   0  91  16   6  83]\n",
      " [ 21  12   0  29   4   1  15]\n",
      " [ 77  47   0  63  11   3 113]]\n",
      "F1-Score :  0.3074398249452954\n",
      "Time Taken : 0.4596216678619385\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.43461552690440824\n",
      "Testing Accuracy :  0.4409277651469826\n",
      "[[549 192 557]\n",
      " [207 139 255]\n",
      " [244 146 453]]\n",
      "F1-Score :  0.4161196207148067\n",
      "Time Taken : 0.4506723880767822\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    print(\"Multinomial Naive Bayes\")\n",
    "    classifier = MultinomialNB();\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(classifier, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    \n",
    "    # predicting test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(classifier, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    \n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = naive_bayes(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = naive_bayes(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2b4ae",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7eeba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.47546980718046683\n",
      "Testing Accuracy :  0.4821274247802906\n",
      "[[1244    6    0    1   23    0   24]\n",
      " [ 282    4    0    0   16    0   18]\n",
      " [  72    0    0    0    2    0    5]\n",
      " [ 171    1    0    0    5    0   15]\n",
      " [ 399    6    0    0   29    0   23]\n",
      " [  72    0    0    0    2    0    8]\n",
      " [ 238    5    0    1   13    0   57]]\n",
      "F1-Score :  0.4865061998541211\n",
      "Time Taken : 163.97067308425903\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.5065658070906809\n",
      "Testing Accuracy :  0.5149482137396462\n",
      "[[1066   32  200]\n",
      " [ 384   49  168]\n",
      " [ 505   34  304]]\n",
      "F1-Score :  0.5175054704595186\n",
      "Time Taken : 140.2228865623474\n"
     ]
    }
   ],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Random Forest Classifier\")\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(rf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "\n",
    "    # predicting test set results\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(rf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = random_forest(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup= random_forest(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa2863",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da0bbcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.4798469149165676\n",
      "Testing Accuracy :  0.4781161501336205\n",
      "F1-Score :  0.49270605397520056\n",
      "[[1259    1    0    0    8    0   30]\n",
      " [ 281    7    0    0   12    0   20]\n",
      " [  68    2    0    0    0    0    9]\n",
      " [ 174    1    0    0    2    0   15]\n",
      " [ 408    4    0    0   18    0   27]\n",
      " [  67    1    0    0    1    0   13]\n",
      " [ 234    3    0    0   10    0   67]]\n",
      "Time Taken : 750.3730466365814\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.5333752334539209\n",
      "Testing Accuracy :  0.5226097882015077\n",
      "F1-Score :  0.5408460977388767\n",
      "[[1051   27  220]\n",
      " [ 377   58  166]\n",
      " [ 430   39  374]]\n",
      "Time Taken : 530.1335372924805\n"
     ]
    }
   ],
   "source": [
    "def sv_classifier(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Support Vector Classifier\")\n",
    "    clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(clf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    \n",
    "    # predicting test set results\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(clf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(cm)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = sv_classifier(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = sv_classifier(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7c50d4e-2529-4da9-894c-ce94d1592514",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inp, output, test_size=0.2, shuffle = True)\n",
    "\n",
    "X_train_copy1 = X_train.copy()\n",
    "X_test_copy1 = X_test.copy()\n",
    "\n",
    "# emotion (7)\n",
    "y_train_emo = y_train[:,0] *1.0\n",
    "y_train_emo = y_train_emo.astype('float')\n",
    "y_test_emo = y_test[:,0] *1.0\n",
    "y_test_emo = y_test_emo.astype('float')\n",
    "\n",
    "# sentiment(3)\n",
    "y_train_senti = y_train[:,1] *1.0\n",
    "y_train_senti = y_train_senti.astype('float')\n",
    "y_test_senti = y_test[:,1] *1.0\n",
    "y_test_senti = y_test_senti.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b9922c-ace3-4bed-89ad-175b08050e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.4842246045987876\n",
      "Testing Accuracy :  0.4762946565088482\n",
      "F1-Score :  0.4883296863603209\n",
      "[[1273    4    0    0    6    0   22]\n",
      " [ 279   10    0    0    6    0   14]\n",
      " [  51    1    0    0    1    0   10]\n",
      " [ 198    1    0    0    1    0   10]\n",
      " [ 445    4    0    0   15    0   19]\n",
      " [  73    1    0    0    0    0    3]\n",
      " [ 245    1    0    0    8    0   41]]\n",
      "Time Taken : 751.3273503780365\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.5345621541317551\n",
      "Testing Accuracy :  0.5123967931075745\n",
      "F1-Score :  0.5320933625091174\n",
      "[[1139   25  141]\n",
      " [ 445   45  124]\n",
      " [ 514   34  275]]\n",
      "Time Taken : 564.9820585250854\n"
     ]
    }
   ],
   "source": [
    "def sv_classifier(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Support Vector Classifier\")\n",
    "    clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(clf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    \n",
    "    # predicting test set results\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(clf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(cm)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = sv_classifier(X_train, y_train_emo, X_test, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = sv_classifier(X_train, y_train_senti, X_test, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140bee0",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c700f2",
   "metadata": {},
   "source": [
    "# Feature Engineering - 1. PCA: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036c3a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846261122193179\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=300, svd_solver='full')\n",
    "X_train1 = pca.fit_transform(X_train.copy())\n",
    "# We keep only 20% data \n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "# 83.3% info retained\n",
    "\n",
    "X_test1 = pca.transform(X_test.copy())\n",
    "\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_test1 = scaler.fit_transform(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460c469",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e58c8044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.46662360265384056\n",
      "Testing Accuracy :  0.42924427957932804\n",
      "[[1165   59    2    5   30    1   40]\n",
      " [ 225   53    0    2   12    0   25]\n",
      " [  51    3    0    1    1    0    6]\n",
      " [ 158   18    2    9    0    0   13]\n",
      " [ 364   28    0    0   34    1   23]\n",
      " [  67    2    0    0    5    1    8]\n",
      " [ 218   30    2    1   19    0   58]]\n",
      "F1-Score :  0.4814004376367615\n",
      "Time Taken : 31.644580602645874\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Logistic Regression\n",
      "Training Accuracy :  0.5072945283347489\n",
      "Testing Accuracy :  0.4609768258146863\n",
      "[[1074   48  180]\n",
      " [ 408   66  132]\n",
      " [ 502   43  289]]\n",
      "F1-Score :  0.5211524434719184\n",
      "Time Taken : 6.857990741729736\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    print(\"Multinomial Logistic Regression\")\n",
    "    start = time.time()\n",
    "    logreg = LogisticRegression(penalty='l2',multi_class='multinomial', max_iter = 1e4, solver = 'lbfgs')\n",
    "    #penalty to handle size better\n",
    "    \n",
    "    #https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451\n",
    "    \n",
    "    logreg.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(logreg, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    accuracy_test_data = cross_val_score(logreg, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = logistic_regression(X_train1, y_train_emo, X_test1, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = logistic_regression(X_train1, y_train_senti, X_test1, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dab036",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82339bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.46817440592653925\n",
      "Testing Accuracy :  0.4748367968303352\n",
      "[[1302    0    0    0    0    0    0]\n",
      " [ 317    0    0    0    0    0    0]\n",
      " [  62    0    0    0    0    0    0]\n",
      " [ 200    0    0    0    0    0    0]\n",
      " [ 450    0    0    0    0    0    0]\n",
      " [  83    0    0    0    0    0    0]\n",
      " [ 328    0    0    0    0    0    0]]\n",
      "F1-Score :  0.474835886214442\n",
      "Time Taken : 0.15608930587768555\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Multinomial Naive Bayes\n",
      "Training Accuracy :  0.4681743643589593\n",
      "Testing Accuracy :  0.47483613205164\n",
      "[[1302    0    0]\n",
      " [ 606    0    0]\n",
      " [ 834    0    0]]\n",
      "F1-Score :  0.474835886214442\n",
      "Time Taken : 0.14336061477661133\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()    \n",
    "    print(\"Multinomial Naive Bayes\")\n",
    "    classifier = MultinomialNB();\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(classifier, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    \n",
    "    # predicting test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(classifier, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    \n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = naive_bayes(X_train1, y_train_emo, X_test1, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = naive_bayes(X_train1, y_train_senti, X_test1, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71a49f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4211ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.46835672133219103\n",
      "Testing Accuracy :  0.4741081993804263\n",
      "[[1287    3    0    0   11    0    1]\n",
      " [ 308    0    0    0    9    0    0]\n",
      " [  61    0    0    0    1    0    0]\n",
      " [ 199    1    0    0    0    0    0]\n",
      " [ 440    2    0    0    8    0    0]\n",
      " [  81    1    0    0    1    0    0]\n",
      " [ 316    0    0    0   10    0    2]]\n",
      "F1-Score :  0.47301239970824216\n",
      "Time Taken : 83.2385904788971\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Random Forest Classifier\n",
      "Training Accuracy :  0.47209568358093057\n",
      "Testing Accuracy :  0.48067621288872936\n",
      "[[1134   21  147]\n",
      " [ 492   22   92]\n",
      " [ 667   14  153]]\n",
      "F1-Score :  0.4773887673231218\n",
      "Time Taken : 69.03017592430115\n"
     ]
    }
   ],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Random Forest Classifier\")\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(rf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "\n",
    "    # predicting test set results\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(rf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = random_forest(X_train1, y_train_emo, X_test1, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup= random_forest(X_train1, y_train_senti, X_test1, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ba441",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46235732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR EMOTIONS (7): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.4706366199571771\n",
      "Testing Accuracy :  0.47447249810538067\n",
      "F1-Score :  0.4759299781181619\n",
      "[[1301    0    0    0    1    0    0]\n",
      " [ 317    0    0    0    0    0    0]\n",
      " [  62    0    0    0    0    0    0]\n",
      " [ 199    0    0    0    1    0    0]\n",
      " [ 448    0    0    0    1    0    1]\n",
      " [  83    0    0    0    0    0    0]\n",
      " [ 325    0    0    0    0    0    3]]\n",
      "Time Taken : 157.43177819252014\n",
      "\n",
      "FOR SENTIMENTS (3): \n",
      "Support Vector Classifier\n",
      "Training Accuracy :  0.5113996178276701\n",
      "Testing Accuracy :  0.49963104782417933\n",
      "F1-Score :  0.5269876002917578\n",
      "[[1226    7   69]\n",
      " [ 501   26   79]\n",
      " [ 630   11  193]]\n",
      "Time Taken : 108.41364884376526\n"
     ]
    }
   ],
   "source": [
    "def sv_classifier(X_train, y_train, X_test, y_test):\n",
    "    start = time.time()\n",
    "    print(\"Support Vector Classifier\")\n",
    "    clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy_train_data = cross_val_score(clf, X_train,y_train,cv=5)\n",
    "    print(\"Training Accuracy : \",np.mean(accuracy_train_data))\n",
    "    \n",
    "    # predicting test set results\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_test_data = cross_val_score(clf, X_test,y_test,cv=5)\n",
    "    print(\"Testing Accuracy : \",np.mean(accuracy_test_data))\n",
    "    # making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1-Score : \",f1)\n",
    "    print(cm)\n",
    "    print(\"Time Taken :\", (time.time()-start))\n",
    "    return np.mean(accuracy_train_data), np.std(accuracy_train_data), np.mean(accuracy_test_data), np.std(accuracy_test_data), f1, time.time()-start\n",
    "\n",
    "\n",
    "print(\"FOR EMOTIONS (7): \")\n",
    "tup = sv_classifier(X_train1, y_train_emo, X_test1, y_test_emo)\n",
    "d = np.asarray(tup)\n",
    "mat = np.append(mat,d)\n",
    "print(\"\\nFOR SENTIMENTS (3): \")\n",
    "tup = sv_classifier(X_train1, y_train_senti, X_test1, y_test_senti)\n",
    "d = np.asarray(tup)\n",
    "mat1 = np.append(mat1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c731bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
